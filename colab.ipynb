{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"colab.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["PVLwrxpoEEEr","aDnVraTOEIsL","8tu19Qn4Ed_p","BhnIfK72DS63","l3mdHLSfD-jr"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"PVLwrxpoEEEr","colab_type":"text"},"source":["## Install dependencies"]},{"cell_type":"code","metadata":{"id":"3Xct6QwTCun4","colab_type":"code","outputId":"59386e96-045d-4bb6-942c-2111fd7bed56","executionInfo":{"status":"ok","timestamp":1556980652059,"user_tz":240,"elapsed":51933,"user":{"displayName":"Gustavo Arango Argoty","photoUrl":"","userId":"02038744119435648834"}},"colab":{"base_uri":"https://localhost:8080/","height":717}},"source":["!pip install tf-nightly-gpu-2.0-preview==2.0.0-dev20190504\n","\n","import tensorflow as tf\n","print(tf.__version__)\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tf-nightly-gpu-2.0-preview\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/50/7369df696cfa8d93010a4acafd6a5b2a5ffc5a7ce6772581c6fef8ba1844/tf_nightly_gpu_2.0_preview-2.0.0.dev20190504-cp36-cp36m-manylinux1_x86_64.whl (346.5MB)\n","\u001b[K     |████████████████████████████████| 346.5MB 59kB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.12.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.15.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.0.9)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.1.0)\n","Collecting wrapt>=1.11.1 (from tf-nightly-gpu-2.0-preview)\n","  Downloading https://files.pythonhosted.org/packages/67/b2/0f71ca90b0ade7fad27e3d20327c996c6252a2ffe88f50a95bba7434eda9/wrapt-1.11.1.tar.gz\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.7.1)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (3.7.1)\n","Collecting tensorflow-estimator-2.0-preview (from tf-nightly-gpu-2.0-preview)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/72/7948e33a345f72ae84b598863b318153bba8c4b367496de5d89825f18cb1/tensorflow_estimator_2.0_preview-1.14.0.dev2019050400-py2.py3-none-any.whl (426kB)\n","\u001b[K     |████████████████████████████████| 430kB 44.5MB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.16.3)\n","Collecting google-pasta>=0.1.2 (from tf-nightly-gpu-2.0-preview)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/bb/f1bbc131d6294baa6085a222d29abadd012696b73dcbf8cf1bf56b9f082a/google_pasta-0.1.5-py3-none-any.whl (51kB)\n","\u001b[K     |████████████████████████████████| 61kB 27.2MB/s \n","\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.2.2)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.0.7)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.33.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.7.1)\n","Collecting tb-nightly<1.15.0a0,>=1.14.0a0 (from tf-nightly-gpu-2.0-preview)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/51/39f71893b4e8ae1f242c2ac03c35b23d97bfb2ddb94c7597ba6fe022b0d5/tb_nightly-1.14.0a20190504-py3-none-any.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 40.1MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tf-nightly-gpu-2.0-preview) (41.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tf-nightly-gpu-2.0-preview) (2.8.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-gpu-2.0-preview) (0.15.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-gpu-2.0-preview) (3.1)\n","Building wheels for collected packages: wrapt\n","  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/89/67/41/63cbf0f6ac0a6156588b9587be4db5565f8c6d8ccef98202fc\n","Successfully built wrapt\n","\u001b[31mERROR: thinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n","Installing collected packages: wrapt, tensorflow-estimator-2.0-preview, google-pasta, tb-nightly, tf-nightly-gpu-2.0-preview\n","  Found existing installation: wrapt 1.10.11\n","    Uninstalling wrapt-1.10.11:\n","      Successfully uninstalled wrapt-1.10.11\n","Successfully installed google-pasta-0.1.5 tb-nightly-1.14.0a20190504 tensorflow-estimator-2.0-preview-1.14.0.dev2019050400 tf-nightly-gpu-2.0-preview-2.0.0.dev20190504 wrapt-1.11.1\n","2.0.0-dev20190504\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aDnVraTOEIsL","colab_type":"text"},"source":["## Integrate Google Drive"]},{"cell_type":"code","metadata":{"id":"RSdXWxcYZ8aK","colab_type":"code","outputId":"7790b3bd-06ed-4b56-c4c2-795dd81ba003","executionInfo":{"status":"ok","timestamp":1556980692997,"user_tz":240,"elapsed":31849,"user":{"displayName":"Gustavo Arango Argoty","photoUrl":"","userId":"02038744119435648834"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8tu19Qn4Ed_p","colab_type":"text"},"source":["## Update Git Repository "]},{"cell_type":"code","metadata":{"id":"rdETFOFoCulD","colab_type":"code","outputId":"976ac3cf-d2a0-454a-c58b-fe8ecd52b0e7","executionInfo":{"status":"ok","timestamp":1556980723346,"user_tz":240,"elapsed":8905,"user":{"displayName":"Gustavo Arango Argoty","photoUrl":"","userId":"02038744119435648834"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%cd /gdrive/Team\\ Drives/umayux/Research/NLP/humor_detection/\n","!git pull\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/gdrive/Team Drives/umayux/Research/NLP/humor_detection\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9NLLvcFsDNRJ","colab_type":"text"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"id":"hUdKK461N0u0","colab_type":"code","outputId":"cd5c4db0-925f-4dd5-ede0-ffee71dfc821","executionInfo":{"status":"error","timestamp":1555779048962,"user_tz":240,"elapsed":8419,"user":{"displayName":"Gustavo Arango","photoUrl":"https://lh4.googleusercontent.com/-Uu1M-nqufbs/AAAAAAAAAAI/AAAAAAAAAeY/-TMCi_1ZbHg/s64/photo.jpg","userId":"06422916416085568647"}},"colab":{"base_uri":"https://localhost:8080/","height":3736}},"source":["%cd /gdrive/Team\\ Drives/umayux/Research/NLP/humor_detection/\n","!python train.py --dataset_file ./data/dataset.tsv --checkpoint_path ./data/ --BATCH_SIZE 1000"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/gdrive/Team Drives/umayux/Research/NLP/humor_detection\n","[2019-05-04 14:40:39,560] INFO - start\n","[2019-05-04 14:40:41,906] INFO - saving parameters to ./data/\n","[2019-05-04 14:40:41,910] INFO - loading dataset\n","2019-05-04 14:40:42.345107: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n","2019-05-04 14:40:42.414756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-05-04 14:40:42.415174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1638] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2019-05-04 14:40:42.415266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-05-04 14:40:42.415687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-05-04 14:40:42.416041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1751] Adding visible gpu devices: 0\n","2019-05-04 14:40:42.416403: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2019-05-04 14:40:42.567357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-05-04 14:40:42.567928: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2033dc0 executing computations on platform CUDA. Devices:\n","2019-05-04 14:40:42.567961: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2019-05-04 14:40:42.570359: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n","2019-05-04 14:40:42.574475: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2034a00 executing computations on platform Host. Devices:\n","2019-05-04 14:40:42.574511: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n","2019-05-04 14:40:42.574698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-05-04 14:40:42.575227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1638] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2019-05-04 14:40:42.575305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-05-04 14:40:42.575892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-05-04 14:40:42.576464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1751] Adding visible gpu devices: 0\n","2019-05-04 14:40:42.576834: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2019-05-04 14:40:42.579169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1179] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-05-04 14:40:42.579199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1185]      0 \n","2019-05-04 14:40:42.579214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1198] 0:   N \n","2019-05-04 14:40:42.579531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-05-04 14:40:42.579942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-05-04 14:40:42.580274: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2019-05-04 14:40:42.580317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1324] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","2019-05-04 14:40:42.619639: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2]\n","\t [[{{node Placeholder/_0}}]]\n","[2019-05-04 14:40:44,480] INFO - SubwordTextEncoder build: trying min_token_count 4878\n","[2019-05-04 14:40:49,657] INFO - SubwordTextEncoder build: trying min_token_count 2439\n","[2019-05-04 14:40:54,415] INFO - SubwordTextEncoder build: trying min_token_count 1219\n","[2019-05-04 14:40:58,898] INFO - SubwordTextEncoder build: trying min_token_count 609\n","[2019-05-04 14:41:03,110] INFO - SubwordTextEncoder build: trying min_token_count 304\n","[2019-05-04 14:41:07,244] INFO - SubwordTextEncoder build: trying min_token_count 152\n","[2019-05-04 14:41:11,106] INFO - SubwordTextEncoder build: trying min_token_count 76\n","[2019-05-04 14:41:14,778] INFO - SubwordTextEncoder build: trying min_token_count 38\n","[2019-05-04 14:41:18,389] INFO - SubwordTextEncoder build: trying min_token_count 19\n","[2019-05-04 14:41:21,885] INFO - SubwordTextEncoder build: trying min_token_count 9\n","[2019-05-04 14:41:25,375] INFO - SubwordTextEncoder build: trying min_token_count 14\n","[2019-05-04 14:41:28,882] INFO - SubwordTextEncoder build: trying min_token_count 11\n","[2019-05-04 14:41:32,522] INFO - SubwordTextEncoder build: trying min_token_count 10\n","2019-05-04 14:41:36.757524: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:41:36.758045: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","[2019-05-04 14:41:36,768] WARNING - The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n","[2019-05-04 14:41:36,770] WARNING - The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n","[2019-05-04 14:41:36,770] WARNING - The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n","[2019-05-04 14:41:36,771] WARNING - The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n","[2019-05-04 14:41:36,772] WARNING - The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n","[2019-05-04 14:41:45,037] INFO - setup learning rate and optimizer\n","[2019-05-04 14:41:45,038] INFO - setup loss function\n","[2019-05-04 14:41:45,052] INFO - Setup transformer model\n","[2019-05-04 14:41:45,111] INFO - input_vocab_size: 10329 classes: 2\n","[2019-05-04 14:41:45,111] INFO - Setup Checkpoints: ./data/\n","[2019-05-04 14:41:45,112] INFO - Initializing from scratch.\n","2019-05-04 14:41:45.115527: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:41:45.115995: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:41:47.858476: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","Epoch 1 Batch 0 Loss 0.4141 Accuracy 0.7900\n","Epoch 1 Train Loss 0.4214 Accuracy 0.7490\n","2019-05-04 14:41:56.433132: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:41:56.433540: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 1 Test Loss 0.4175 Accuracy 0.7545\n","Saving checkpoint for epoch 1 at ./data/ckpt-1\n","Time taken for 1 epoch: 13.847522020339966 secs\n","\n","2019-05-04 14:41:58.962953: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:41:58.963464: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 2 Batch 0 Loss 0.4137 Accuracy 0.7900\n","Epoch 2 Train Loss 0.4212 Accuracy 0.7490\n","2019-05-04 14:42:09.552802: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:42:09.553153: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 2 Test Loss 0.4175 Accuracy 0.7545\n","Time taken for 1 epoch: 12.757763862609863 secs\n","\n","2019-05-04 14:42:11.720755: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:42:11.721229: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 3 Batch 0 Loss 0.4134 Accuracy 0.7900\n","Epoch 3 Train Loss 0.4211 Accuracy 0.7490\n","2019-05-04 14:42:22.990567: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:42:22.990967: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 3 Test Loss 0.4175 Accuracy 0.7545\n","Time taken for 1 epoch: 13.413252115249634 secs\n","\n","2019-05-04 14:42:25.133982: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:42:25.134512: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 4 Batch 0 Loss 0.4134 Accuracy 0.7900\n","Epoch 4 Train Loss 0.4210 Accuracy 0.7490\n","2019-05-04 14:42:35.712609: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:42:35.712990: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 4 Test Loss 0.4173 Accuracy 0.7545\n","Time taken for 1 epoch: 12.739703893661499 secs\n","\n","2019-05-04 14:42:37.873769: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:42:37.874241: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 5 Batch 0 Loss 0.4130 Accuracy 0.7900\n","Epoch 5 Train Loss 0.4136 Accuracy 0.7484\n","2019-05-04 14:42:48.530028: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:42:48.530406: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 5 Test Loss 0.3999 Accuracy 0.7475\n","Time taken for 1 epoch: 12.812184572219849 secs\n","\n","2019-05-04 14:42:50.686005: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:42:50.686541: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 6 Batch 0 Loss 0.4207 Accuracy 0.7600\n","Epoch 6 Train Loss 0.4107 Accuracy 0.7481\n","2019-05-04 14:43:02.384176: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:43:02.384576: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 6 Test Loss 0.4042 Accuracy 0.7499\n","Time taken for 1 epoch: 13.86544394493103 secs\n","\n","2019-05-04 14:43:04.551456: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:43:04.551937: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 7 Batch 0 Loss 0.4181 Accuracy 0.7610\n","Epoch 7 Train Loss 0.4132 Accuracy 0.7455\n","2019-05-04 14:43:15.106707: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:43:15.107105: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 7 Test Loss 0.4006 Accuracy 0.7582\n","Saving checkpoint for epoch 7 at ./data/ckpt-2\n","Time taken for 1 epoch: 12.856893301010132 secs\n","\n","2019-05-04 14:43:17.408511: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:43:17.408982: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 8 Batch 0 Loss 0.4004 Accuracy 0.7960\n","Epoch 8 Train Loss 0.4051 Accuracy 0.7526\n","2019-05-04 14:43:27.959839: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:43:27.960207: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 8 Test Loss 0.3962 Accuracy 0.7611\n","Saving checkpoint for epoch 8 at ./data/ckpt-3\n","Time taken for 1 epoch: 12.871946334838867 secs\n","\n","2019-05-04 14:43:30.280490: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:43:30.280989: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 9 Batch 0 Loss 0.4014 Accuracy 0.7950\n","Epoch 9 Train Loss 0.4013 Accuracy 0.7583\n","2019-05-04 14:43:40.879965: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:43:40.880341: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 9 Test Loss 0.3990 Accuracy 0.7571\n","Time taken for 1 epoch: 12.775585651397705 secs\n","\n","2019-05-04 14:43:43.055984: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:43:43.056517: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 10 Batch 0 Loss 0.4033 Accuracy 0.7940\n","Epoch 10 Train Loss 0.3989 Accuracy 0.7635\n","2019-05-04 14:43:53.633026: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:43:53.633397: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 10 Test Loss 0.4007 Accuracy 0.7526\n","Time taken for 1 epoch: 12.729564189910889 secs\n","\n","2019-05-04 14:43:55.785604: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:43:55.786140: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 11 Batch 0 Loss 0.4043 Accuracy 0.7810\n","Epoch 11 Train Loss 0.3948 Accuracy 0.7699\n","2019-05-04 14:44:06.324772: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:44:06.325144: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 11 Test Loss 0.3987 Accuracy 0.7566\n","Time taken for 1 epoch: 12.691611051559448 secs\n","\n","2019-05-04 14:44:08.477192: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2019-05-04 14:44:08.477707: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","Epoch 12 Batch 0 Loss 0.4016 Accuracy 0.7800\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BhnIfK72DS63","colab_type":"text"},"source":["## Test the model"]},{"cell_type":"code","metadata":{"id":"4DgF6kv0DWCu","colab_type":"code","outputId":"902f3459-afd5-4545-ef1a-662af9468010","executionInfo":{"status":"ok","timestamp":1556332679934,"user_tz":240,"elapsed":9343,"user":{"displayName":"Gustavo Arango Argoty","photoUrl":"","userId":"02038744119435648834"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%cd /gdrive/Team\\ Drives/umayux/Research/NLP/chatbot/transformer/\n","\n","import tensorflow_datasets as tfds\n","import tensorflow as tf\n","import utensor.dataset as dt\n","from utensor.optimizer import CustomSchedule, loss_function\n","from utensor.model import Transformer\n","import time\n","from utensor.masking import create_masks\n","import pickle\n","import matplotlib.pyplot as plt\n","\n","\n","\n","checkpoint_path=\"./data/banco/\"\n","d_model = 128\n","MAX_LENGTH=60\n","BUFFER_SIZE=20000\n","BATCH_SIZE=64\n","num_heads=8\n","num_layers=4\n","d_model=128\n","dff=512\n","dropout_rate=0.1\n","\n","\n","\n","def restore():\n","    \n","    # loading tokenizers for future predictions\n","    tokenizer_source = pickle.load(open(checkpoint_path + './tokenizer_source.pickle', 'rb'))\n","    tokenizer_target = pickle.load(open(checkpoint_path + './tokenizer_target.pickle', 'rb'))\n","\n","    input_vocab_size = tokenizer_source.vocab_size + 2\n","    target_vocab_size = tokenizer_target.vocab_size + 2\n","\n","    learning_rate = CustomSchedule(d_model)\n","    optimizer = tf.keras.optimizers.Adam(\n","        learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n","    )\n","\n","    transformer = Transformer(\n","        num_layers,\n","        d_model,\n","        num_heads,\n","        dff,\n","        input_vocab_size,\n","        target_vocab_size,\n","        dropout_rate,\n","    )\n","\n","\n","    ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n","    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n","\n","    # if a checkpoint exists, restore the latest checkpoint.\n","    if ckpt_manager.latest_checkpoint:\n","        ckpt.restore(ckpt_manager.latest_checkpoint)\n","        print(\"Latest checkpoint restored!!\")\n","    else:\n","        print(\"Initializing from scratch.\")\n","        \n","    return transformer, tokenizer_source, tokenizer_target\n","\n","\n","           \n","    \n","def evaluate(inp_sentence):\n","    start_token = [tokenizer_source.vocab_size]\n","    end_token = [tokenizer_source.vocab_size + 1]\n","\n","    # inp sentence is portuguese, hence adding the start and end token\n","    inp_sentence = start_token + tokenizer_source.encode(inp_sentence) + end_token\n","    encoder_input = tf.expand_dims(inp_sentence, 0)\n","\n","    # as the target is english, the first word to the transformer should be the\n","    # english start token.\n","    decoder_input = [tokenizer_target.vocab_size]\n","    output = tf.expand_dims(decoder_input, 0)\n","\n","    for i in range(MAX_LENGTH):\n","        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n","            encoder_input, output)\n","\n","        # predictions.shape == (batch_size, seq_len, vocab_size)\n","        predictions, attention_weights = transformer(encoder_input, \n","                                                     output,\n","                                                     False,\n","                                                     enc_padding_mask,\n","                                                     combined_mask,\n","                                                     dec_padding_mask)\n","\n","        # select the last word from the seq_len dimension\n","        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n","\n","        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","\n","        # return the result if the predicted_id is equal to the end token\n","        if tf.equal(predicted_id, tokenizer_target.vocab_size+1):\n","            return tf.squeeze(output, axis=0), attention_weights\n","\n","        # concatentate the predicted_id to the output which is given to the decoder\n","        # as its input.\n","        output = tf.concat([output, predicted_id], axis=-1)\n","\n","    return tf.squeeze(output, axis=0), attention_weights\n","\n","\n","\n","def translate(sentence):\n","    result, attention_weights = evaluate(sentence)\n","\n","    predicted_sentence = tokenizer_target.decode([i for i in result \n","                                            if i < tokenizer_target.vocab_size])  \n","\n","    print('Pregunta: {}'.format(sentence))\n","    print('Respuesta UmyBot: {}'.format(predicted_sentence))\n","\n","\n","\n","transformer, tokenizer_source, tokenizer_target = restore()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/gdrive/Team Drives/umayux/Research/NLP/chatbot/transformer\n","Latest checkpoint restored!!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vDO-wQ-E56qb","colab_type":"code","outputId":"b5d9eec9-22ed-44b6-9e99-a22559aa291f","executionInfo":{"status":"ok","timestamp":1556332690782,"user_tz":240,"elapsed":7998,"user":{"displayName":"Gustavo Arango Argoty","photoUrl":"","userId":"02038744119435648834"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["translate('banco_falabella dicen que no están operativo')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Pregunta: banco_falabella dicen que no están operativo\n","Respuesta UmyBot: hola @fefith, hemos realizado pruebas de transferencia y no presentamos inconvenientes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QLpF3esoFT31","colab_type":"code","outputId":"dbac0380-e193-41c6-aa6d-83b2fe582987","executionInfo":{"status":"ok","timestamp":1556254883833,"user_tz":240,"elapsed":2903,"user":{"displayName":"Gustavo Arango Argoty","photoUrl":"","userId":"02038744119435648834"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["translate('@bancolombia #bancoeterno se cagaron literalmente el servicio. ahora son menos filas pero más demoras con el servicio.')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Pregunta: @bancolombia #bancoeterno se cagaron literalmente el servicio. ahora son menos filas pero más demoras con el servicio.\n","Respuesta UmyBot: ¡hola! cuéntanos por favor si haces referencia a un poco más de tu comentario, para poder ayudarte. saludos. ana\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"l3mdHLSfD-jr","colab_type":"text"},"source":["## Predict examples"]},{"cell_type":"code","metadata":{"id":"a2ebWi0cUzow","colab_type":"code","outputId":"c3e562e0-d5fd-4f58-cfa7-f631383ca55c","executionInfo":{"status":"ok","timestamp":1556252317547,"user_tz":240,"elapsed":1220,"user":{"displayName":"Gustavo Arango Argoty","photoUrl":"","userId":"02038744119435648834"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%cd /gdrive/Team\\ Drives/umayux/Research/NLP/chatbot/transformer/\n","\n","import tensorflow_datasets as tfds\n","import tensorflow as tf\n","import utensor.dataset as dt\n","from utensor.optimizer import CustomSchedule, loss_function\n","from utensor.model import Transformer\n","import time\n","from utensor.masking import create_masks\n","import pickle\n","import matplotlib.pyplot as plt\n","\n","checkpoint_path=\"./data/banco/\"\n","d_model = 128\n","MAX_LENGTH=40\n","BUFFER_SIZE=20000\n","BATCH_SIZE=64\n","num_heads=8\n","num_layers=4\n","dff=512\n","dropout_rate=0.1\n","\n","def restore():\n","\n","    # loading tokenizers for future predictions\n","    tokenizer_source = pickle.load(open(checkpoint_path+'/tokenizer_source.pickle', 'rb'))\n","    tokenizer_target = pickle.load(open(checkpoint_path+'/tokenizer_target.pickle', 'rb'))\n","\n","    input_vocab_size = tokenizer_source.vocab_size + 2\n","    target_vocab_size = tokenizer_target.vocab_size + 2\n","\n","    learning_rate = CustomSchedule(d_model)\n","    optimizer = tf.keras.optimizers.Adam(\n","        learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n","    )\n","\n","    transformer = Transformer(\n","        num_layers,\n","        d_model,\n","        num_heads,\n","        dff,\n","        input_vocab_size,\n","        target_vocab_size,\n","        dropout_rate,\n","    )\n","\n","    ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n","    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n","\n","    # if a checkpoint exists, restore the latest checkpoint.\n","    if ckpt_manager.latest_checkpoint:\n","        ckpt.restore(ckpt_manager.latest_checkpoint)\n","        print(\"Latest checkpoint restored!!\")\n","    else:\n","        print(\"Initializing from scratch.\")\n","\n","    return transformer, tokenizer_source, tokenizer_target\n","        \n","\n","        \n","def evaluate(inp_sentence):\n","    start_token = [tokenizer_source.vocab_size]\n","    end_token = [tokenizer_source.vocab_size + 1]\n","    \n","    \n","    # inp sentence is portuguese, hence adding the start and end token\n","    inp_sentence = start_token + tokenizer_source.encode(inp_sentence) + end_token\n","    encoder_input = tf.expand_dims(inp_sentence, 0)\n","\n","    # as the target is english, the first word to the transformer should be the\n","    # english start token.\n","    decoder_input = [tokenizer_target.vocab_size]\n","    output = tf.expand_dims(decoder_input, 0)\n","\n","    for i in range(40):\n","        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n","        encoder_input, output)\n","\n","    # predictions.shape == (batch_size, seq_len, vocab_size)\n","    predictions, attention_weights = transformer(encoder_input, \n","                                                 output,\n","                                                 False,\n","                                                 enc_padding_mask,\n","                                                 combined_mask,\n","                                                 dec_padding_mask)\n","\n","    # select the last word from the seq_len dimension\n","    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n","\n","    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","\n","    # return the result if the predicted_id is equal to the end token\n","    if tf.equal(predicted_id, tokenizer_target.vocab_size+1):\n","        return tf.squeeze(output, axis=0), attention_weights\n","\n","    # concatentate the predicted_id to the output which is given to the decoder\n","    # as its input.\n","    output = tf.concat([output, predicted_id], axis=-1)\n","\n","    return tf.squeeze(output, axis=0), attention_weights\n","\n","\n","\n","\n","def translate(sentence, plot=''):\n","    \n","    result, attention_weights = evaluate(sentence)\n","\n","    predicted_sentence = tokenizer_target.decode([i for i in result \n","                                            if i < tokenizer_target.vocab_size])  \n","\n","    print('Pregunta: {}'.format(sentence))\n","    print('Respuesta UmyBot: {}'.format(predicted_sentence))\n","\n","    #   if plot:\n","    #     plot_attention_weights(attention_weights, sentence, result, plot)\n","\n","    \n","    \n","transformer, tokenizer_source, tokenizer_target = restore()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/gdrive/Team Drives/umayux/Research/NLP/chatbot/transformer\n","Latest checkpoint restored!!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0xqAvczzvMok","colab_type":"code","outputId":"96cc8f2c-4309-44af-950c-768042801af8","executionInfo":{"status":"ok","timestamp":1556252323817,"user_tz":240,"elapsed":1518,"user":{"displayName":"Gustavo Arango Argoty","photoUrl":"","userId":"02038744119435648834"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["sentence = '@bancolombia #bancoeterno se cagaron literalmente el servicio. ahora son menos filas pero más demoras con el servicio.'\n","translate(sentence, plot='')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Pregunta: @bancolombia #bancoeterno se cagaron literalmente el servicio. ahora son menos filas pero más demoras con el servicio.\n","Respuesta UmyBot: ¡\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"97w-DBMBn3JE","colab_type":"code","colab":{}},"source":["import pandas as pd\n","data = pd.read_csv('./data/banco/bancobot.tsv.test', sep='\\t', names=['source', 'target'])\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1DOJWQxVCuLm","colab_type":"code","colab":{}},"source":["\n","for ix,i in data.iterrows():\n","    translate(\n","        i['source']\n","    )\n","    print(\"Respuesta Humano: {}\".format(i['target']))\n","    print('\\n\\n')\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ISiMWAVqft2e","colab_type":"code","colab":{}},"source":["def plot_attention_weights(attention, sentence, result, layer, tokenizer_source, tokenizer_target):\n","  fig = plt.figure(figsize=(30, 38))\n","  \n","  sentence = tokenizer_source.encode(sentence)\n","  \n","  attention = tf.squeeze(attention[layer], axis=0)\n","  \n","  for head in range(attention.shape[0]):\n","    ax = fig.add_subplot(8, 1, head+1)\n","    \n","    # plot the attention weights\n","    ax.matshow(attention[head][:-1, :], cmap='viridis')\n","\n","    fontdict = {'fontsize': 10}\n","    \n","    ax.set_xticks(range(len(sentence)+2))\n","    ax.set_yticks(range(len(result)))\n","    \n","    ax.set_ylim(len(result)-1.5, -0.5)\n","        \n","    ax.set_xticklabels(\n","        ['<start>']+[tokenizer_source.decode([i]) for i in sentence]+['<end>'], \n","        fontdict=fontdict, rotation=90)\n","    \n","    ax.set_yticklabels([tokenizer_target.decode([i]) for i in result \n","                        if i < tokenizer_target.vocab_size], \n","                       fontdict=fontdict)\n","    \n","    ax.set_xlabel('Head {}'.format(head+1))\n","  \n","  plt.tight_layout()\n","  plt.show()"],"execution_count":0,"outputs":[]}]}